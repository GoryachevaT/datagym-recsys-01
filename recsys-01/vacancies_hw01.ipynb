{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, json, gzip, re\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pymystem3\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from scipy.sparse import csc_matrix, csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 14s, sys: 37.4 s, total: 1min 51s\n",
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with gzip.open('vacancies.json.gzip') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. prepr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 string feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].apply(clean_html)\n",
    "df['key_skills_str'] = df['key_skills'].apply(lambda x: ' '.join([el['name'] for el in x]) if x!=[] else None)\n",
    "df['driver_license_str'] = df['driver_license_types'].apply(lambda x: ' '.join([el['id'] for el in x]) \n",
    "                                                            if x!=[] else None).fillna('no_info')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 salary feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "currency_df = df[['area.name', 'salary.currency', 'id']]\\\n",
    "                            .groupby(['area.name', 'salary.currency'])\\\n",
    "                            .count()\\\n",
    "                            .sort_values('id', ascending=False)\n",
    "currency_df['rnk'] = currency_df.groupby('area.name').cumcount()\n",
    "currency_df = currency_df[currency_df['rnk']==0].reset_index()\\\n",
    "                                                .rename(columns={'salary.currency': 'freq_currency'})\\\n",
    "                                                .drop(['rnk', 'id'], axis=1)\n",
    "\n",
    "df = df.merge(currency_df, on=['area.name'], how='left')\n",
    "df['salary.currency'] = df['salary.currency'].fillna(df['freq_currency']).fillna('RUR')\n",
    "currency_mapper = {'RUR': 1, 'BYR': 29.62, 'KZT': 0.16, 'UAH': 2.72, \n",
    "                   'USD': 73, 'UZS': 0.0077, 'EUR': 80, \n",
    "                   'KGS': 0.95, 'AZN': 43.41, 'GEL': 23.39}\n",
    "\n",
    "df['salary.gross'] = df['salary.gross'].fillna(df['salary.gross'].value_counts().index[0])\n",
    "\n",
    "df['salary_from_rur'] = df[['salary.from', 'salary.currency', 'salary.gross']]\\\n",
    "   .apply(lambda x: x[0]*currency_mapper[x[1]]*0.83 if x[2] else x[0]*currency_mapper[x[1]], axis=1)\n",
    "\n",
    "df['salary_to_rur'] = df[['salary.to', 'salary.currency', 'salary.gross']]\\\n",
    "   .apply(lambda x: x[0]*currency_mapper[x[1]]*0.83 if x[2] else x[0]*currency_mapper[x[1]], axis=1)\n",
    "df['salary_gap'] = df['salary_to_rur'] - df['salary_from_rur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary_from_rur'] = df[['salary.from', 'salary.currency', 'salary.gross']]\\\n",
    "   .apply(lambda x: x[0]*currency_mapper[x[1]]*0.83 if x[2] else x[0]*currency_mapper[x[1]], axis=1)\n",
    "\n",
    "df['salary_to_rur'] = df[['salary.to', 'salary.currency', 'salary.gross']]\\\n",
    "   .apply(lambda x: x[0]*currency_mapper[x[1]]*0.83 if x[2] else x[0]*currency_mapper[x[1]], axis=1)\n",
    "df['salary_gap'] = df['salary_to_rur'] - df['salary_from_rur']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bin feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = [x for x in df['salary_from_rur'].quantile(q=np.linspace(0, 1, 11)).values]\n",
    "labels = [i*10 for i, x in enumerate(bin_edges)][1:]\n",
    "df['salary_from_rur_bins'] = pd.cut(df['salary_from_rur'], bins=bin_edges, labels=labels, include_lowest=True)\\\n",
    "                                    .cat.add_categories('0').fillna('0').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = sorted(list(set([x for x in df['salary_to_rur'].quantile(q=np.linspace(0, 1, 11)).values])))\n",
    "labels = [i*10 for i, x in enumerate(bin_edges)][1:]\n",
    "df['salary_to_rur_bins'] = pd.cut(df['salary_to_rur'], bins=bin_edges, labels=labels, include_lowest=True)\\\n",
    "                                    .cat.add_categories('0').fillna('0').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = sorted(list(set([x for x in df['salary_gap'].quantile(q=np.linspace(0, 1, 11)).values])))\n",
    "labels = [i*10 for i, x in enumerate(bin_edges)][1:]\n",
    "df['salary_gap_bins'] = pd.cut(df['salary_gap'], bins=bin_edges, labels=labels, include_lowest=True)\\\n",
    "                                    .cat.add_categories('0').fillna('0').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_freq_areas = 50\n",
    "freq_areas = df['area.name'].value_counts().head(n_freq_areas).index\n",
    "df['freq_area'] = df['area.name'].apply(lambda x: x if x in freq_areas else 'Other')\n",
    "\n",
    "ohe_cols = ['salary.currency', 'salary.gross', 'experience.name', \n",
    "            'schedule.name', 'employment.name', 'freq_area', 'salary_from_rur_bins', \n",
    "            'salary_to_rur_bins', 'salary_gap_bins']\n",
    "\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "ohe.fit(df[ohe_cols])\n",
    "ohe_matrix = ohe.transform(df[ohe_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_df = pd.DataFrame(ohe_matrix.todense(), columns=ohe.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 flag cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['with_address'] = df['address.raw'].apply(lambda x: 1 if x else 0)\n",
    "df['with_metro'] = df['address.metro.line_name'].apply(lambda x: 1 if x else 0)\n",
    "df['driver_license_flg'] = df['driver_license_str'].apply(lambda x: 1 if x!='no_info' else 0)\n",
    "df['salary_gross_flg'] = df['salary.gross'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver_license_str - ohe ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 tf idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(data):\n",
    "    data = data.lower()\n",
    "    cleantext = re.sub('[^a-zа-яё0-9]', ' ', data).split()\n",
    "    lemm_mystem = [mystem.lemmatize(x)[0] for x in cleantext]\n",
    "    tokens_stem = [wordnet_lemmatizer.lemmatize(x, pos=wordnet.VERB) for x in lemm_mystem]\n",
    "    return [x for x in tokens_stem if x not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = pymystem3.Mystem()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stop_words = [\"еще\", \"него\", \"сказать\", \"а\", \"ж\", \"нее\", \"со\", \"без\", \"же\", \"ней\", \"совсем\", \"более\", \"жизнь\", \n",
    "          \"нельзя\", \"так\", \"больше\", \"за\", \"нет\", \"такой\", \"будет\", \"зачем\", \"ни\", \"там\", \"будто\", \"здесь\", \n",
    "          \"нибудь\", \"тебя\", \"бы\", \"и\", \"никогда\", \"тем\", \"был\", \"из\", \"ним\", \"теперь\", \"была\", \"из\", \"за\",\n",
    "          \"них\", \"то\", \"были\", \"или\", \"ничего\", \"тогда\", \"было\", \"им\", \"но\", \"того\", \"быть\", \"иногда\", \"ну\", \n",
    "          \"тоже\", \"в\", \"их\", \"о\", \"только\", \"вам\", \"к\", \"об\", \"том\", \"вас\", \"кажется\", \"один\", \"тот\", \"вдруг\",\n",
    "          \"как\", \"он\", \"три\", \"ведь\", \"какая\", \"она\", \"тут\", \"во\", \"какой\", \"они\", \"ты\", \"вот\", \"когда\", \"опять\",\n",
    "          \"у\", \"впрочем\", \"конечно\", \"от\", \"уж\", \"все\", \"которого\", \"перед\", \"уже\", \"всегда\", \"которые\", \"по\",\n",
    "          \"хорошо\", \"всего\", \"кто\", \"под\", \"хоть\", \"всех\", \"куда\", \"после\", \"чего\", \"всю\", \"ли\", \"потом\", \"человек\",\n",
    "          \"вы\", \"лучше\", \"потому\", \"чем\", \"г\", \"между\", \"почти\", \"через\", \"где\", \"меня\", \"при\", \"что\", \"говорил\",\n",
    "          \"мне\", \"про\", \"чтоб\", \"да\", \"много\", \"раз\", \"чтобы\", \"даже\", \"может\", \"разве\", \"чуть\", \"два\", \"можно\",\n",
    "          \"с\", \"эти\", \"для\", \"мой\", \"сам\", \"этого\", \"до\", \"моя\", \"свое\", \"этой\", \"другой\", \"мы\", \"свою\", \"этом\",\n",
    "          \"его\", \"на\", \"себе\", \"этот\", \"ее\", \"над\", \"себя\", \"эту\", \"ей\", \"надо\", \"сегодня\", \"я\", \"ему\", \"наконец\",\n",
    "          \"сейчас\", \"если\", \"нас\", \"сказал\", \"есть\", \"не\", \"сказала\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df['clean_name'] = df['name'].apply(clean_text)\n",
    "# df['clean_descr'] = df['description'].apply(clean_text)\n",
    "# df['clean_skills'] = df['key_skills_str'].fillna('').apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['clean_name_wo_sw'] = [[word for word in x if word not in stop_words] for x in df['clean_name'].values]\n",
    "# df['clean_descr_wo_sw'] = [[word for word in x if word not in stop_words] for x in df['clean_descr'].values]\n",
    "# df['clean_skills_wo_sw'] = [[word for word in x if word not in stop_words] for x in df['clean_skills'].values]\n",
    "# df[['clean_name_wo_sw', 'clean_descr_wo_sw', 'clean_skills_wo_sw']].to_pickle('clean_text.pickle') \n",
    "\n",
    "# text_name = [' '.join(x) for x in df['clean_name_wo_sw'].values]\n",
    "# text_descr = [' '.join(x) for x in df['clean_descr_wo_sw'].values]\n",
    "# text_skills = [' '.join(x) for x in df['clean_skills_wo_sw'].values]\n",
    "\n",
    "text_df = pd.read_pickle('clean_text.pickle')\n",
    "\n",
    "text_name = [' '.join(x) for x in text_df['clean_name_wo_sw'].values]\n",
    "text_descr = [' '.join(x) for x in text_df['clean_descr_wo_sw'].values]\n",
    "text_skills = [' '.join(x) for x in text_df['clean_skills_wo_sw'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_name = TfidfVectorizer(max_features=500)\n",
    "tfidf_name.fit(text_name)\n",
    "name_matrix = tfidf_name.transform(text_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_descr = TfidfVectorizer(max_features=2000)\n",
    "tfidf_descr.fit(text_descr)\n",
    "descr_matrix = tfidf_descr.transform(text_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_skills = TfidfVectorizer(max_features=1000)\n",
    "tfidf_skills.fit(text_skills)\n",
    "skills_matrix = tfidf_skills.transform(text_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = np.hstack((name_matrix.todense(), descr_matrix.todense(), skills_matrix.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_features = [f'name_{x}' for x in tfidf_name.get_feature_names()] + \\\n",
    "                 [f'descr_{x}' for x in tfidf_descr.get_feature_names()] + \\\n",
    "                 [f'skills_{x}' for x in tfidf_skills.get_feature_names()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix = df[['with_address', 'with_metro', 'driver_license_flg', 'salary_gross_flg']].copy() # 'address.lat', 'address.lng'\n",
    "fin_feature_cols = list(df_matrix.columns) + list(ohe_df.columns) + tfidf_features \n",
    "fin_feature_matrix = np.hstack((df_matrix.values, ohe_df.values, tfidf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_feature_matrix = csr_matrix(fin_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# cs = cosine_similarity(sparse_feature_matrix)\n",
    "dist_out = pairwise_distances(sparse_feature_matrix, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
